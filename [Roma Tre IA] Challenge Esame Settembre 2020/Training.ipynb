{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializzazione del dataset\n",
    "\n",
    "Il dataset è composto da due sotto file in formato .csv:\n",
    "1. trainingData, è un dataframe pandas creato a partire dal file di training \"train.csv\"\n",
    "2. testData, è un dataframe pandas creato a partire dal file di testing \"test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('train.csv')\n",
    "testData = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo iniziale del TrainData set\n",
    "\n",
    "Una volta caricato il TrainData set controllo che i dati presenti all'interno siano corretti, ovvero che non vi siano campi nulli o NaN. In questo caso la ricerca dei duplicati è futile poiché non abbiamo conoscenza sull'identità del paziente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = trainData.isnull()\n",
    "for column in trainData:\n",
    "    print(column)\n",
    "    print(missing_data[column].value_counts())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_data = trainData.isna()\n",
    "for column in trainData:\n",
    "    print(column)\n",
    "    print(NaN_data[column].value_counts())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo iniziale del TestData set\n",
    "\n",
    "Una volta caricato il TrainData set controllo che i dati presenti all'interno siano corretti, ovvero che non vi siano campi nulli o NaN. In questo caso la ricerca dei duplicati è futile poiché non abbiamo conoscenza sull'identità del paziente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = testData.isnull()\n",
    "for column in testData:\n",
    "    print(column)\n",
    "    print(missing_data[column].value_counts())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è necessario eliminare le righe dove vi sono dei valori NaN poiché non possiamo aggiungere dati manualmente, potremmo creare delle discrepanze che la ridotta mole di dati non compenserebbe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_data = testData.isna()\n",
    "for column in testData:\n",
    "    print(column)\n",
    "    print(NaN_data[column].value_counts())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo dettagliato del trainData set\n",
    "\n",
    "Una volta controllata la presenza di valori nulli o duplicati all'interno del dataset è possibile analizzarne nel dettaglio le varie colonne. Questa analisi supporta la successiva operazione di feature selection, che verrà effettuata analizzando sia i singoli grafici DEATH_EVENT - feature e sia la correlation map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(trainData.columns):\n",
    "    plt.figure(i)\n",
    "    sns.lineplot(x='DEATH_EVENT',y=col, data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(trainData.corr(), annot=True, fmt='.1g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = trainData.corr()\n",
    "correlation_target = abs(correlation[\"DEATH_EVENT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scegliamo di filtrare i nostri dati per ottenere solo le features più correlate con la feature target. Per questo viene impostata una soglia di correlazione minima pari a 0.1, in questo modo tutte le feature a correlazione molto bassa vengono scartate poiché non interessanti. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = correlation_target[correlation_target > 0.1]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analisi della heatmap e della corrleazione tra le varie condizioni mediche del paziente fanno emergere un forte collegamento tra la possibile morte durante il periodo di osservazione con le seguenti caratteristiche:\n",
    "1. L'età del paziente\n",
    "2. La Ejection Fraction, ovvero la frazione di eiezione è la frazione volumetrica del fluido espulsa da una camera ad ogni contrazione, un valore normale è compreso tra 50 e 75 \n",
    "3. la concentrazione nel siero di creatina e sodio\n",
    "4. Il tempo di osservazione, più il paziente è sotto osservazione e più è probabile che sia posssibile tenere traccia di un possibile un arresto cardiaco\n",
    "\n",
    "L'analisi dei grafici valida questa decisione, inoltre si nota come la feature \"smoking\" e \"sex\" potrebbero essere correlate tra loro, ovvero che l'incidenza di arresti cardiaci potrebbe anche essere collegata al binomio genere-fumatore.\n",
    "\n",
    "Istanzio una struttura dati chiamata selectedFeatures all'interno della quale inserisco le label delle feature scelte in seguito all'analisi dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"age\", \"creatinine_phosphokinase\", \"ejection_fraction\", \"serum_creatinine\", \"serum_sodium\", \"time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializzazione Modello: RandomForest\n",
    "\n",
    "Il modello scelto è un classificatore RandomForest. Il classificatore RandomForest utilizza diversi classificatori Decision Tree su diversi sotto campioni del dataset di input. Ogni classificatore compierà un'operazione di fitting sul suo sottocampione. Il classificatore RandomForest utilizzerà una funzione di averaging, ovvero fa la media tra le varie predizioni, per migliorare l'accuratezza e tenere sotto controllo l'overfitting. \n",
    "\n",
    "Un Decision tree classifier ha il compito di predirre il valore della variabile target, nel nostro caso DEATH_EVENT, apprendendo delle regole di decisione a partire dalle feature del nostro dataset\n",
    "\n",
    "Il classificatore viene poi valutato in accuratezza, tramite la metrica accuracy_score, sia sul dataset di training che su quello di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = trainData[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest = testData[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainData[\"DEATH_EVENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = testData[\"DEATH_EVENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=6, n_estimators=32, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(datasetTrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_TrainingSet = clf.predict(datasetTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_TestSet = clf.predict(datasetTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuratezza\n",
    "\n",
    "L'accuratezza viene calcolata usando le previsioni prodotte dal modello sia sul trainingSet che sul testSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set accuracy: {:.2f}\".format(clf.score(datasetTrain, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set accuracy: {:.2f}\".format(accuracy_score(y_test, predict_TestSet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, predict_TestSet),annot=True)\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusioni\n",
    "\n",
    "Il nostro dataset è caratterizzato da una ridotta quantità di dati, questo comporta un rischio di overfitting che potrebbe inficiare le prestazioni del nostro modello. Per controllarne la validità possiamo effettuare un controllo sulla sua accuratezza sfruttando la K-Fold Cross Validation, nello specifico la 10-Fold Cross Validation.\n",
    "\n",
    "Inoltre è da notare come il dataset sia sbilanciato verso i dati relativi alle persone che non hanno subito arresti cardiaci, ovvero la presenza di dati relativi ai decessi è molto esigua e questo potrebbe inficiare sul processo di addestramento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, datasetTest, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy using K-Fold Cross Validation, with k=10 : %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
