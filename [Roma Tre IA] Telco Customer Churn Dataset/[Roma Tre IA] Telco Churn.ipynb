{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dei dati\n",
    "\n",
    "In questa porzione di notebook avviene il caricamento del dataset da una file .csv tramite la creazione di un DataFrame Pandas. \n",
    "Un DataFrame Pandas è un \"Two-dimensional, size-mutable, potentially heterogeneous tabular data.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data = pd.read_csv(\"Telco.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo del Dataset\n",
    "\n",
    "Una volta caricato il Dataset controllo che i dati presenti all'interno siano corretti, ovvero che rispettino le seguenti caratteristiche:\n",
    "\n",
    "1. Assenza di campi nulli o NaN \n",
    "2. Assenza di duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = telco_data.isnull().sum(axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_data = telco_data.isna().sum(axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = telco_data.duplicated(['customerID'], keep=False).sum(axis=0)\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizzazione delle informazioni\n",
    "\n",
    "Una volta controllata la correttezza dei dati possiamo visualizzarli utilizzando la libreria \"seaborn\".\n",
    "\n",
    "Seaborn si basa su matplotlib e viene utilizzata per plottare come varia la feature di interesse Churn per ogni feature secondaria del dataset.\n",
    "\n",
    "L'operazione è abbastanza esosa di tempo e risorse ma permette di avere una visione completa dei dati in analisi. \n",
    "Per ottenere risultati consistenti è possibile accorpare i valori \"No internet service\" con \"No\" nelle colonne d'interesse poiché significano la stessa cosa, stessa cosa per \"No phone service\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data = telco_data.replace(to_replace=['No phone service', 'No internet service'], value='No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo ciclo for permette di realizzare un grafo per ogni feature presente nel dataset, ad eccezione di Churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, predictor in enumerate(telco_data.drop(columns=['Churn'])):\n",
    "    plt.figure(i)\n",
    "    sns.countplot(data=telco_data, x=predictor, hue='Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoding \n",
    "\n",
    "Il dataset contiene valori non numerici, è necessario trasformare tutte le feature in valori numerici per renderli compatibili con gli algoritmi di classificazione\n",
    "\n",
    "La funzione Label Encoding permette di codificare tutti i dati non numerici, i label appunto, in valori compresi tra 0 e N-1 dove N sono il numero di valori univoci presenti all'interno delle colonne\n",
    "\n",
    "Le colonne da sistemare vengono ricavate dalla struttura dati X, che contiene l'intero dataset\n",
    "\n",
    "La funzione lambda permette di applicare la funzione di traformazione offerta da LabelEncoder su tutte le colonne da sistemare. \n",
    "\n",
    "Dopo l'esecuzione dell'encoding viene stampata la tabella contenente le colonne trasformate, che potrebbe omettere alcune colonne presenti all'interno del dataset poiché non soggette ad encoding, e la tabella completa per visualizzare il contenuto di X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = telco_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_encode = X.dtypes == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns[features_to_encode].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[columns] = X[columns].apply(lambda col: le.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Feature Selection\n",
    "\n",
    "Dall'analisi dei dati, grazie ai grafici, è posssible eliminare alcune colonne poiché non significative per la predizione del Churn.\n",
    "Le colonne che verranno eliminate, ovvero droppate, saranno: \n",
    "1. customerID poichè non è un'informazione rilevamente\n",
    "2. gender poiché non presenta delle variazioni significative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data = telco_data.drop(columns=['customerID', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = telco_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializzazione e apprendimento del modello\n",
    "\n",
    "Il modello scelto è un classificatore RandomForest. Il classificatore RandomForest utilizza diversi classificatori Decision Tree su diversi sotto campioni del dataset di input. Ogni classificatore compierà un'operazione di fitting sul suo sottocampione. Il classificatore RandomForest utilizzerà una funzione di averaging, ovvero fa la media tra le varie predizioni, per migliorare l'accuratezza e tenere sotto controllo l'overfitting. \n",
    "\n",
    "Un Decision tree classifier ha il compito di predirre il valore della variabile target, nel nostro caso Churn, apprendendo delle regole di decisione a partire dalle feature del nostro dataset\n",
    "\n",
    "Per selezionare le feature da utilizzare usiamo la funzione SelectFromModel offerta da scikit_learn. Questa funzione rimuove le features meno importanti, ovvero che incidono poco sull'accuratezza della predizione, restituendo un insieme di features che massimizzano l'accuratezza della predizione. \n",
    "\n",
    "SelectFromModel utilizza come metrica di valutazione un valore di threshold, che di default è la mediana tra i valori di predizione. Se il valore associato ad una feature supera la threashold verrà considerata, altrimenti verrà scartata. Il RandomForestClassifier utilizza 1000 stimatori, ovvero Decision Trees su sottocampioni di dataset, per sperimentare più combinazioni possibili, a costo di un tempo di esecuzione lievemente maggiore del solito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = telco_data.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = SelectFromModel(RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= feature_selector.get_support()\n",
    "telco_data.columns[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features= X_train.columns[(feature_selector.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = telco_data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set accuracy: {:.2f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set predictions:\", clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.YlGn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
