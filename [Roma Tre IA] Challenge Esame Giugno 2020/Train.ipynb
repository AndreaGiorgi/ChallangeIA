{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializzazione del dataset\n",
    "\n",
    "Il dataset è composto da due sotto file in formato .csv:\n",
    "1. trainingData, è un dataframe pandas creato a partire dal file di training \"train.csv\"\n",
    "2. testData, è un dataframe pandas creato a partire dal file di testing \"test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo iniziale del TrainData set\n",
    "\n",
    "Una volta caricato il TrainData set controllo che i dati presenti all'interno siano corretti, ovvero che rispettino le seguenti caratteristiche:\n",
    "\n",
    "1. Assenza di campi nulli o NaN\n",
    "2. Assenza di duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = trainData.isnull().sum(axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_data = trainData.isna().sum(axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = trainData.duplicated(['AppointmentID'], keep=False).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo iniziale del TestData set\n",
    "\n",
    "Una volta caricato il TestData set controllo che i dati presenti all'interno siano corretti, ovvero che rispettino le seguenti caratteristiche:\n",
    "\n",
    "1. Assenza di campi nulli o NaN\n",
    "2. Assenza di duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = testData.isnull().sum(axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_data = testData.isna().sum(axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = testData.duplicated(['AppointmentID'], keep=False).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo dettagliato del trainData set\n",
    "\n",
    "Una volta controllata la presenza di valori nulli o duplicati all'interno del dataset è possibile analizzarne nel dettaglio le varie colonne. Questo controllo supporta tutte le operazioni successive, dalla correzione dei dati errati fino alla feature engineering. \n",
    "\n",
    "Per semplificare l'analisi dei dati trasformo \"No-show\" da \"Yes\\No\" a 1\\0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['No-show'].replace(\"No\", 0, inplace=True)\n",
    "trainData['No-show'].replace(\"Yes\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(trainData.Age.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"Age\", y=\"No-show\", data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(trainData.Neighbourhood.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"Neighbourhood\", y=\"No-show\", data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainData.Handcap.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"Handcap\", y=\"No-show\", data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainData['No-show'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo dettagliato del testData set\n",
    "\n",
    "Una volta controllata la presenza di valori nulli o duplicati all'interno del dataset è possibile analizzarne nel dettaglio le varie colonne. Questo controllo supporta tutte le operazioni successive, dalla correzione dei dati errati fino alla feature engineering. \n",
    "\n",
    "Per semplificare l'analisi dei dati trasformo \"No-show\" da \"Yes\\No\" a 1\\0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['No-show'].replace(\"No\", 0, inplace=True)\n",
    "testData['No-show'].replace(\"Yes\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correzione del trainData\n",
    "\n",
    "Il trainData set potrebbe contenere dei dati non conformi alle analisi successive, come ad esempio dei campi vuoti, per questo è necessario compiere delle operazioni preliminari di correzione e normalizzazione. Le operazioni si concentrano sulle feature più importanti che saranno oggetto di valutazione successiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione feature Age\n",
    "\n",
    "Dall'analisi del dataset si nota come alcuni pazienti superano i 100 anni di età, potrebbe essere un errore di raccolta dei dati. Come prima operazione andiamo ad eliminare i valori di età inferiori a 0, che sicuramente sono errori, e quelli superiori a 100.\n",
    "\n",
    "Successivamente verrà effettuato un controllo sulla colonna, se contiene valori nulli allora questi verranno rimpiazzati con la mediana della colonna riempendo i campi vuoti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData[(trainData.Age >= 0) & (trainData.Age <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainData.Age.isnull().sum(axis=0) > 0:\n",
    "    print(trainData.Age.isnull().sum(axis=0))\n",
    "    dataset = trainData.Age.fillna(trainData.Age.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione feature Gender\n",
    "\n",
    "Anche il Gender potrebbe contenere dei valori nulli, per evitarlo riempiamo i campi vuoti con il valore 0. Probabilmente questa scelta introdurrà un piccolo bias all'interno del dataset, ma ci eviterà di effettuare analisi su una feature incompleta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainData.Gender.isnull().sum(axis=0) > 0:\n",
    "    print(trainData.Gender.isnull().sum(axis=0))\n",
    "    trainData = trainData.Gender.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione feature No-show\n",
    "\n",
    "La colonna No-show è la colonna target della nostra classificazione, non possiamo avere dei campi nulli o non consistenti al suo interno. Aggiungendo dei valori 0 o 1 rischiamo di introdurre un bias troppo elevato, per questo eliminiamo eventuali righe contenenti valori nulli di No-show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainData[\"No-show\"].isnull().sum(axis=0) > 0:\n",
    "    print(trainData[\"No-show\"].isnull().sum(axis=0))\n",
    "    trainData = trainData[\"No-show\"].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione features ScheduledDay, AppointmentDay e PatientID\n",
    "\n",
    "Queste feature sono utilizzate durante la fase di feature engineering per la creazione di nuove feature, è dunque necessario che queste non siano vuote. Nel caso in cui si incontrassero delle righe contenenti valori inconsistenti si può solo che ricorrere alla loro eliminazione, poiché l'inserimento di valori a posteriori potrebbe creare dei bias o delle problematiche durante l'addestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainData.ScheduledDay.isnull().sum(axis=0) > 0:\n",
    "    print(trainData.ScheduledDay.isnull().sum(axis=0))\n",
    "    trainData = trainData.ScheduledDay.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainData.AppointmentDay.isnull().sum(axis=0) > 0:\n",
    "    print(trainData.AppointmentDay.isnull().sum(axis=0))\n",
    "    trainData = trainData.AppointmentDay.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainData.PatientId.isnull().sum(axis=0) > 0:\n",
    "    print(trainData.PatientId.isnull().sum(axis=0))\n",
    "    trainData = trainData.PatientId.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correzione del testData\n",
    "\n",
    "Il testData set potrebbe contenere dei dati non conformi alle analisi successive, come ad esempio dei campi vuoti, per questo è necessario compiere delle operazioni preliminari di correzione e normalizzazione. \n",
    "\n",
    "Le operazioni si concentrano sulle feature più importanti che saranno oggetto di valutazione successiva. Le motivazioni sull'utilizzo di queste funzioni di correzioni sono le stesse di quelle sul training set. Ometto i commenti relativi per ridurre la dimensione del notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione feature Age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = testData[(testData.Age >= 0) & (testData.Age <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testData.Age.isnull().sum(axis=0) > 0:\n",
    "    print(testData.Age.isnull().sum(axis=0))\n",
    "    dataset = testData.Age.fillna(testData.Age.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione feature Gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testData.Gender.isnull().sum(axis=0) > 0:\n",
    "    print(testData.Gender.isnull().sum(axis=0))\n",
    "    testData = testData.Gender.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione feature No-show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testData[\"No-show\"].isnull().sum(axis=0) > 0:\n",
    "    print(testData[\"No-show\"].isnull().sum(axis=0))\n",
    "    testData = testData[\"No-show\"].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione features ScheduledDay, AppointmentDay e PatientID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testData.ScheduledDay.isnull().sum(axis=0) > 0:\n",
    "    print(testData.ScheduledDay.isnull().sum(axis=0))\n",
    "    testData = testData.ScheduledDay.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testData.AppointmentDay.isnull().sum(axis=0) > 0:\n",
    "    print(testData.AppointmentDay.isnull().sum(axis=0))\n",
    "    testData = testData.AppointmentDay.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testData.PatientId.isnull().sum(axis=0) > 0:\n",
    "    print(testData.PatientId.isnull().sum(axis=0))\n",
    "    testData = testData.PatientId.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Osservando le informazioni sul dataset è possibile andare a compiere delle modifiche sulle varie features per migliorarne l'usabilità e la comprensione. Inoltre verranno eliminate PatientID e AppointmentID poiché poco rilevanti.\n",
    "\n",
    "Per semplificare l'analisi dei dati trasformo \"Gender\" da \"F\\M\" a 0\\1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['Gender'].replace(\"F\", 0, inplace=True)\n",
    "trainData['Gender'].replace(\"M\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Gender'].replace(\"F\", 0, inplace=True)\n",
    "testData['Gender'].replace(\"M\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature WaitingDays\n",
    "\n",
    "Osservando il dataset posso assumere che ScheduledDay e AppointmentDay sono due feature importanti, probabilmente molto correlate con la variabile target No-show. \n",
    "\n",
    "Utilizzo gli strumenti offerti da NumPy e Pandas al fine di creare una nuova colonna, che chiamerò WaitingDays, che conterrà il numero di giorni che un paziente attende prima di poter essere visitato. \n",
    "\n",
    "Questa scelta è motivata dal fatto che potrebbe esserci una correlazione tra i giorni di attesa e il non presentarsi ad un appuntamento, magari l'assenza è frutto di una dimenticanza data dal tempo. \n",
    "\n",
    "Dalla analisi del grafo sembrerebbe che il numero di giorni di attesa incidano molto sul presentarsi o meno ad un appuntamento, probabilmente a causa di una dimenticanza dovuta dalla troppa attesa, soprattutto al superamento dei 100 giorni. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[['ScheduledDay', 'AppointmentDay']] = trainData[['ScheduledDay', 'AppointmentDay']].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['WaitingDays'] = trainData[\"AppointmentDay\"].sub(trainData[\"ScheduledDay\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[\"WaitingDays\"] = (trainData[\"WaitingDays\"]).abs().dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.drop(columns=['ScheduledDay', 'AppointmentDay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"WaitingDays\", y=\"No-show\", data=trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData[['ScheduledDay', 'AppointmentDay']] = testData[['ScheduledDay', 'AppointmentDay']].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['WaitingDays'] = testData[\"AppointmentDay\"].sub(testData[\"ScheduledDay\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData[\"WaitingDays\"] = (testData[\"WaitingDays\"]).abs().dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = testData.drop(columns=['ScheduledDay', 'AppointmentDay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature MissedPastAppointment \n",
    "\n",
    "Oltre che i giorni di attesa prima di essere visitati è utile andare ad analizzare il numero di appuntamenti nei quali un paziente non si è presentato. Questa analisi è motivata dal fatto che potrebbe esserci una correlazione tra il numero di appuntamenti saltati nel passato e il non presentarsi in futuro. \n",
    "\n",
    "La feature viene realizzatra raggruppando per PatientId e sommando il numero di No-show associati. Questo è supportato dal fatto che la feature PatientId contiene dei duplicati, ovvero ci sono più prenotazioni effettuate dallo stesso paziente per appuntamenti diversi\n",
    "\n",
    "Dall'analisi del grafo risulta che vi è un alta correlazione tra il numero di appuntamenti saltati nel passato e il non presentarsi ad un successivo appuntamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['MissedPastAppointments'] = trainData.groupby('PatientId')['No-show'].apply(lambda x: x.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"MissedPastAppointments\", y=\"No-show\", data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.drop(columns=['PatientId', 'AppointmentID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['MissedPastAppointments'] = testData.groupby('PatientId')['No-show'].apply(lambda x: x.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = testData.drop(columns=['PatientId', 'AppointmentID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoding \n",
    "\n",
    "Il dataset contiene valori non numerici, è necessario trasformare tutte le feature in valori numerici per renderli compatibili con gli algoritmi di classificazione\n",
    "\n",
    "La funzione Label Encoding permette di codificare tutti i dati non numerici, i label appunto, in valori compresi tra 0 e N-1 dove N sono il numero di valori univoci presenti all'interno delle colonne\n",
    "\n",
    "Le colonne da sistemare vengono ricavate dalla struttura dati X, che contiene l'intero dataset\n",
    "\n",
    "La funzione lambda permette di applicare la funzione di traformazione offerta da LabelEncoder su tutte le colonne da sistemare. \n",
    "\n",
    "Dopo l'esecuzione dell'encoding viene stampata la tabella contenente le colonne trasformate, che potrebbe omettere alcune colonne presenti all'interno del dataset poiché non soggette ad encoding, e la tabella completa per visualizzare il contenuto di X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mask = trainData.dtypes==object\n",
    "columns = trainData.columns[feature_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "trainData[columns] = trainData[columns].apply(lambda col: le.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mask = testData.dtypes==object\n",
    "columns = testData.columns[feature_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "testData[columns] = testData[columns].apply(lambda col: le.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializzazione Modello \n",
    "\n",
    "Il modello scelto è un classificatore RandomForest. Il classificatore RandomForest utilizza diversi classificatori Decision Tree su diversi sotto campioni del dataset di input. Ogni classificatore compierà un'operazione di fitting sul suo sottocampione. Il classificatore RandomForest utilizzerà una funzione di averaging, ovvero fa la media tra le varie predizioni, per migliorare l'accuratezza e tenere sotto controllo l'overfitting. \n",
    "\n",
    "Un Decision tree classifier ha il compito di predirre il valore della variabile target, nel nostro caso Churn, apprendendo delle regole di decisione a partire dalle feature del nostro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = trainData.drop(columns = ['No-show'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest = testData.drop(columns = ['No-show'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainData[\"No-show\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = testData[\"No-show\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(datasetTrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_TestSet = clf.predict(datasetTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_TrainingSet = clf.predict(datasetTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set accuracy: {:.2f}\".format(accuracy_score(y_train, predict_TrainingSet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set accuracy: {:.2f}\".format(accuracy_score(y_test, predict_TestSet)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
